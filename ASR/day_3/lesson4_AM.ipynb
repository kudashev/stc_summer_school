{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Урок 4\n",
    "\n",
    "В этом уроке мы перейдем от DTW к распознованию по эталонному словарю. \n",
    "\n",
    "Эталон в графе теперь будет задаваться как последовательность фонем из словаря. Словарь для да/нет (daNetDict.txt) выглядит следующим образом:\n",
    "\n",
    "da: SIL d aa SIL<br>\n",
    "net: SIL n ee t SIL<br>\n",
    "\n",
    "Словарь для цифр (digitDict.txt):\n",
    "\n",
    "0: SIL n ay ll SIL<br>\n",
    "1: SIL a dd ii n SIL<br>\n",
    "2: SIL d v aa SIL<br>\n",
    "3: SIL t rr ii SIL<br>\n",
    "4: SIL ch i t yy rr e SIL<br>\n",
    "5: SIL pp aa tt SIL<br>\n",
    "6: SIL sh ee s tt SIL<br>\n",
    "7: SIL ss ee mm SIL<br>\n",
    "8: SIL v oo ss ae mm SIL<br>\n",
    "9: SIL dd ee vv ae tt SIL<br>\n",
    "\n",
    "SIL здесь – это фонема паузы. \n",
    "\n",
    "Каждой фонеме будет сопоставлен наиболее типичный для нее вектор признаков. В данном случае мы будем использовать среднее значение вектора признаков фонем, взятых из обучающего набора. Будем назвать это акустической моделью, которая уже храниться в файле outAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь граф уже строится на основе словаря. Узлы теперь представляют собой отдельные фонемы с переходом только в себя и следующий узел (переходов через несколько узлов уже не будет, так как пропуск фонемы в слове нежелателен). Набор используемых фонем и их вектора признаков (AMs - экземпляр класса AcoModelSet, который представляет собой словарь: ключ - фонема, который указывает на акустическую модель этой фонемы - экземпляр класса AcoModel) определяются акустической моделью, загружаемой с помощью AcoModels из outAM. Загрузить акустическую модель можно следующим способом: AMs = AcoModels.loadAcoModelSet(file_AMs). Схема такого графа для да/нет (для цифр по аналогии) представлена ниже:\n",
    "\n",
    "<img src=\"graph_4.jpg\">\n",
    "\n",
    "<b>Задание 1:</b> \n",
    "- Написать функцию для чтения словаря.\n",
    "- Разобраться с описанием класса AcoModel из файла AcoModels.py\n",
    "- Реализовать граф на основе словаря и загруженной акустической модели AMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import FtrFile\n",
    "import AcoModels\n",
    "\n",
    "\n",
    "class State:\n",
    "    # model - экземляр класса AcoModel\n",
    "    def __init__(self, model, idx): \n",
    "        self.model = model\n",
    "        self.word = None\n",
    "        self.isFinal = False\n",
    "        self.nextStates = []\n",
    "        self.idx = idx\n",
    "        self.bestToken = None\n",
    "        self.currentWord = None\n",
    "\n",
    "\n",
    "# rxfilename - файл словаря\n",
    "def load_graph(rxfilename, AMs):\n",
    "    \n",
    "    startState = State(None, 0)\n",
    "    graph = [startState, ]\n",
    "    stateIdx = 1\n",
    "    #--------------------TODO--------------------------------------------\n",
    "    \n",
    "    #---------------------------------------------------------------------\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка графа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** SEE graph.txt ***\n",
      "*** END DEBUG. GRAPH ***\n"
     ]
    }
   ],
   "source": [
    "def check_graph(graph):\n",
    "    assert len(graph) > 0, \"graph is empty.\"\n",
    "    assert graph[0].model is None \\\n",
    "        and graph[0].word is None \\\n",
    "        and not graph[0].isFinal, \"broken start state in graph.\"\n",
    "    idx = 0\n",
    "    for state in graph:\n",
    "        assert state.idx == idx\n",
    "        idx += 1\n",
    "        assert (state.isFinal and state.word is not None) \\\n",
    "            or (not state.isFinal and state.word is None)\n",
    "\n",
    "\n",
    "def print_graph(graph):\n",
    "    with open('graph.txt', 'w') as fn:\n",
    "        np.set_printoptions(formatter={'float': '{: 0.1f}'.format})\n",
    "        for state in graph:\n",
    "            nextStatesIdxs = [s.idx for s in state.nextStates]\n",
    "            if state.idx == 0:\n",
    "                model_name = 'None'\n",
    "            else:\n",
    "                model_name = state.model.name    \n",
    "            fn.write(\"State: idx={} word={} isFinal={} nextStatesIdxs={} model={} \\n\".format(\n",
    "                state.idx, state.word, state.isFinal, nextStatesIdxs, model_name))\n",
    "    print(\"*** SEE graph.txt ***\")\n",
    "    print(\"*** END DEBUG. GRAPH ***\")\n",
    "\n",
    "\n",
    "file_etalons = \"daNetDict.txt\" \n",
    "#file_etalons = \"digitDict.txt\"\n",
    "file_AMs = \"outAM\"\n",
    "# загрузка акустической модели из уже готового файла outAM:\n",
    "AMs = AcoModels.loadAcoModelSet(file_AMs)\n",
    "    \n",
    "graph = load_graph(file_etalons, AMs)\n",
    "                   \n",
    "check_graph(graph)\n",
    "# Сохранить граф в читабельном виде в файл graph.txt:\n",
    "print_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь дистанция будет считаться как евклидово расстояние признаков кадра записи от признаков фонемы в эталоне с помощью метода dist класса акустической модели.\n",
    "\n",
    "<b>Задание 2:</b> Вычислить дистанцию токена с помощью метода класса AcoModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Token:\n",
    "    def __init__(self, state, dist=0.0, sentence=\"\"):\n",
    "        self.state = state\n",
    "        self.dist = dist\n",
    "        self.sentence = sentence\n",
    "        self.alive = True\n",
    "        \n",
    "        \n",
    "def findBest(Tokens):\n",
    "    minDist = None\n",
    "    bestToken = 0\n",
    "    for token in Tokens:\n",
    "        if token.alive:\n",
    "            if not minDist:\n",
    "                minDist = token.dist\n",
    "                bestToken = token\n",
    "            elif token.dist <= minDist:\n",
    "                minDist = token.dist\n",
    "                bestToken = token\n",
    "    return bestToken\n",
    "\n",
    "\n",
    "def beamPurnning(nextTokens):\n",
    "    thr_common = 150        \n",
    "    bestToken = findBest(nextTokens)\n",
    "    bestDist = bestToken.dist\n",
    "    for i in range(len(nextTokens)):\n",
    "        if nextTokens[i].alive and nextTokens[i].dist > bestDist + thr_common:\n",
    "            nextTokens[i].alive = False\n",
    "    return nextTokens, bestDist\n",
    "\n",
    "\n",
    "def statePrunning(nextTokens):\n",
    "    for i in range(len(nextTokens)):\n",
    "        state_index = nextTokens[i].state.idx\n",
    "        if not graph[state_index].bestToken:\n",
    "            graph[state_index].bestToken = nextTokens[i]\n",
    "        else:\n",
    "            if nextTokens[i].dist <= graph[state_index].bestToken.dist:\n",
    "                graph[state_index].bestToken.alive = False\n",
    "                graph[state_index].bestToken = nextTokens[i]\n",
    "            else:\n",
    "                nextTokens[i].alive = False\n",
    "    for token in nextTokens:                           # cleaning the bestTokens\n",
    "        index = token.state.idx                        #\n",
    "        if graph[index].bestToken:                     #\n",
    "            graph[index].bestToken = None\n",
    "    \n",
    "    return nextTokens\n",
    "\n",
    "\n",
    "def recognize(rec_results, features, graph):\n",
    "\n",
    "    startTime = time.time()\n",
    "    print(\"-\" * 20)\n",
    "    startState = graph[0]\n",
    "    activeTokens = [Token(startState), ]\n",
    "    nextTokens = []\n",
    "\n",
    "    for frame in range(features.nSamples):\n",
    "        ftrCurrentFrameRecord = features.readvec()\n",
    "        for token in activeTokens:\n",
    "            if token.alive:\n",
    "                for transitionState in token.state.nextStates:\n",
    "                    newToken = Token(transitionState, token.dist, token.sentence)\n",
    "                    #----------------------TODO---------------------------------------\n",
    "                    #newToken.dist += \n",
    "                    #-----------------------------------------------------------------\n",
    "                    nextTokens.append(newToken)\n",
    "        nextTokens = statePrunning(nextTokens)               \n",
    "        nextTokens,bestDist = beamPurnning(nextTokens)        \n",
    "\n",
    "        activeTokens = nextTokens\n",
    "        nextTokens = []                                    \n",
    "\n",
    "    finalTokens = []\n",
    "    for token in activeTokens:\n",
    "        if token.state.isFinal and token.alive:\n",
    "            finalTokens.append(token)\n",
    "\n",
    "    if len(finalTokens) != 0:\n",
    "        winToken = findBest(finalTokens)\n",
    "    else:\n",
    "        winToken = findBest(activeTokens)\n",
    "        winToken.state.word = winToken.state.currentWord\n",
    "\n",
    "    print(\"result: {} ==> {}\".format(filename, winToken.state.word))\n",
    "    endTime = time.time()\n",
    "    print(\"time: {} sec\".format(round(endTime - startTime, 2)))\n",
    "\n",
    "    etalons_word = filename.split('_')[0]\n",
    "    records_word = winToken.state.word.split('_')[0]\n",
    "    rec_results.append(etalons_word == records_word)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Здесь поддерживается распознавание да/нет и одиночных цифр. Для выбора первого варианта в коде ниже нужно указать <br> \"base = 1\", а для второго – любое другое значение отличное от 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "result: da_06 ==> da\n",
      "time: 0.04 sec\n",
      "--------------------\n",
      "result: da_07 ==> da\n",
      "time: 0.04 sec\n",
      "--------------------\n",
      "result: da_08 ==> da\n",
      "time: 0.04 sec\n",
      "--------------------\n",
      "result: da_09 ==> da\n",
      "time: 0.04 sec\n",
      "--------------------\n",
      "result: da_10 ==> da\n",
      "time: 0.04 sec\n",
      "--------------------\n",
      "result: da_11 ==> da\n",
      "time: 0.06 sec\n",
      "--------------------\n",
      "result: da_12 ==> da\n",
      "time: 0.04 sec\n",
      "--------------------\n",
      "result: da_13 ==> da\n",
      "time: 0.06 sec\n",
      "--------------------\n",
      "result: da_14 ==> da\n",
      "time: 0.05 sec\n",
      "--------------------\n",
      "result: da_15 ==> da\n",
      "time: 0.06 sec\n",
      "--------------------\n",
      "result: da_16 ==> da\n",
      "time: 0.05 sec\n",
      "--------------------\n",
      "result: da_17 ==> da\n",
      "time: 0.05 sec\n",
      "--------------------\n",
      "result: da_18 ==> da\n",
      "time: 0.07 sec\n",
      "--------------------\n",
      "result: da_19 ==> da\n",
      "time: 0.05 sec\n",
      "--------------------\n",
      "result: net_06 ==> net\n",
      "time: 0.04 sec\n",
      "--------------------\n",
      "result: net_07 ==> net\n",
      "time: 0.06 sec\n",
      "--------------------\n",
      "result: net_08 ==> net\n",
      "time: 0.06 sec\n",
      "--------------------\n",
      "result: net_09 ==> net\n",
      "time: 0.07 sec\n",
      "--------------------\n",
      "result: net_10 ==> net\n",
      "time: 0.04 sec\n",
      "--------------------\n",
      "result: net_11 ==> net\n",
      "time: 0.05 sec\n",
      "--------------------\n",
      "result: net_12 ==> net\n",
      "time: 0.05 sec\n",
      "--------------------\n",
      "result: net_13 ==> net\n",
      "time: 0.08 sec\n",
      "--------------------\n",
      "result: net_14 ==> net\n",
      "time: 0.09 sec\n",
      "--------------------\n",
      "result: net_15 ==> net\n",
      "time: 0.07 sec\n",
      "--------------------\n",
      "result: net_16 ==> net\n",
      "time: 0.05 sec\n",
      "--------------------\n",
      "result: net_17 ==> net\n",
      "time: 0.08 sec\n",
      "--------------------\n",
      "result: net_18 ==> net\n",
      "time: 0.06 sec\n",
      "--------------------\n",
      "result: net_19 ==> net\n",
      "time: 0.09 sec\n",
      "--------------------\n",
      "result: net_20 ==> net\n",
      "time: 0.07 sec\n",
      "--------------------\n",
      "result: net_21 ==> net\n",
      "time: 0.05 sec\n",
      "--------------------\n",
      "WER is: 0.0\n",
      "Total time: 0 min 1.9 sec\n",
      "RTF is: 0.023\n"
     ]
    }
   ],
   "source": [
    "    import time\n",
    "    \n",
    "    base = 1\n",
    "    if base == 1:\n",
    "        file_etalons = \"daNetDict.txt\"\n",
    "        records = \"ark,t:records_daNet_mfcc.txtftr\"\n",
    "        #records = \"ark,t:DaNetStreet_mfcc.txtftr\"\n",
    "    else:\n",
    "        file_etalons = \"digitDict.txt\"\n",
    "        records = \"ark,t:records_digit_mfcc.txtftr\"\n",
    "        #records = \"ark,t:DigitStreet_mfcc.txtftr\"\n",
    "\n",
    "    file_AMs = \"outAM\"\n",
    "\n",
    "    rec_results = []\n",
    "    s_time = time.time()\n",
    "    numbFrame = 0\n",
    "\n",
    "    # загрузка акустической модели из уже готового файла outAM:\n",
    "    AMs = AcoModels.loadAcoModelSet(file_AMs)\n",
    "    \n",
    "    graph = load_graph(file_etalons, AMs)\n",
    "    for filename, features in FtrFile.FtrDirectoryReader(records):\n",
    "        frame = recognize(rec_results, features, graph)\n",
    "        numbFrame += frame\n",
    "    print(\"-\" * 20)\n",
    "    print(\"WER is: {}\".format(round(1 - sum(rec_results) / len(rec_results), 3)))\n",
    "\n",
    "    time = time.time() - s_time\n",
    "    minut = int(time / 60)\n",
    "    second = time - minut * 60\n",
    "    print(\"Total time: {} min {} sec\".format(minut, round(second,2)))\n",
    "    rtf = time / (numbFrame * 0.01)\n",
    "    print(\"RTF is: {}\".format(round(rtf,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы уже, наверное, заметили, такой вариант распознавания работает значительно быстрее расcмотренного DTW, да и WER теперь для да/нет вообще равен нулю."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
