{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Урок 2\n",
    "\n",
    "В этом уроке мы реализуем DTW алгоритм на основе token passing algorithm (TPA).\n",
    "\n",
    "Начнем с того, что у нас есть несколько эталонов (высказываний) и одна запись. Необходимо определить, к какому из эталонов наша запись \"ближе\" с точки зрения дистанции (сумарного евклидовго расстояния), полученной с помощью DTW.\n",
    "\n",
    "Для тренировки будем использовать искусственные одномерные признаки:\n",
    "\n",
    "запись [<br>\n",
    "0<br>\n",
    "0.9<br>\n",
    "1.3<br>\n",
    "0<br>\n",
    "]<br>\n",
    "\n",
    "эталон-да [<br>\n",
    "0<br>\n",
    "1<br>\n",
    "2<br>\n",
    "0<br>\n",
    "]\n",
    "\n",
    "эталон-нет [<br>\n",
    "0<br>\n",
    "1<br>\n",
    "0<br>\n",
    "]\n",
    "\n",
    "Они уже записаны в формате ark и хранятся в файлах record_mfcc.txtftr и etalons_mfcc.txtftr соответственно. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала нужно реализовать функцию load_graph, которая построит граф на основе используемых эталонов. Каждая его ветвь будет одним из эталонов. Эталоны состоят из узлов типа State. Класс State имеет следующие атрибуты:\n",
    "\n",
    "- ftr – вектор признаков узла;<br>\n",
    "- isFinal – является ли этот узел финальным в слове;<br>\n",
    "- word – слово эталона (назначается только для финального узла ветви);<br> \n",
    "- nextState – список узлов, к которым в данном узле есть переход;<br>\n",
    "- idx – индекс узла;<br>\n",
    "\n",
    "На данном этапе узлы в графе будут иметь переходы только в себя и следующий state. Нулевой узел является корневым и имеет переходы в начальные узлы каждой ветви. Финальный узел каждой ветви имеет переход только в себя.\n",
    "\n",
    "Такой граф представлен ниже:\n",
    "\n",
    "<img src=\"graph_1.jpg\">\n",
    "\n",
    "<br>\n",
    "Теперь попробуем реализовать такой граф:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import FtrFile\n",
    "\n",
    "class State:\n",
    "    def __init__(self, ftr, idx):  \n",
    "        self.ftr = ftr           \n",
    "        self.isFinal = False     \n",
    "        self.word = None               \n",
    "        self.nextStates = []     \n",
    "        self.idx = idx           \n",
    "\n",
    "def load_graph(rxfilename):\n",
    "    startState = State(None, 0)\n",
    "    graph = [startState, ]\n",
    "    stateIdx = 1\n",
    "    for word, features in FtrFile.FtrDirectoryReader(rxfilename):\n",
    "        prevState = startState\n",
    "        for frame in range(features.nSamples):\n",
    "            state = State(features.readvec(), stateIdx)\n",
    "            state.nextStates.append(state)  # add loop\n",
    "            prevState.nextStates.append(state)\n",
    "            prevState = state \n",
    "            graph.append(state)\n",
    "            stateIdx += 1\n",
    "        if state:\n",
    "            state.word = word\n",
    "            state.isFinal = True\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее идет описание класса Token и самого алгоритма TPA:\n",
    "\n",
    "- Алгоритм TPA двигается последовательно по кадрам записи и на каждом кадре берёт множество токенов от предыдущего кадра, и порождает множество токенов для текущего кадра.\n",
    "- Один токен – это штука, олицетворяющая собой один из возможных вариантов разметки (соотнесения кадров записи кадрам эталона), заканчивающаяся на данном кадре. По токену должно быть можно понять, какую суммарную дистанцию набрал данный токен (то есть то, насколько он хорош), в какой узле графа эталонов он находится (чтобы от него можно было породить токен для следующего кадра), и через какие слова он прошёл (чтобы по лучшему токену можно было получить результат).\n",
    "- На некотором кадре всё множество токенов описывает все возможные разметки, которые можно получить к данному кадру. После обработки последнего кадра, мы просто переберём все финальные токены (разметки) и выберем лучший (та, которая имеет минимальное суммарное расстояние от записи до эталона).\n",
    "- Финальные токены – это токены, которым соответствует законченная разметка (то есть та, в которой после финального кадра мы оказались на финальном узле графа). Остальные токены – фактически, бракованные.\n",
    "\n",
    "Получается, что TPA (в том виде,в котором он тут описан) – это удобная форма записи полного перебора всех возможных разметок.\n",
    "\n",
    "Теперь определим класс Token, функцию distance для вычисления евклидова расстояния между двумя векторами и главную функцию recognize, в которой и определяется наилучший токен для текущей записи, посредством работы TPA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Token:\n",
    "    def __init__(self, state, dist=0.0, sentence=\"\"):\n",
    "        self.state = state        # узел графа, в котором находится токен\n",
    "        self.dist = dist          # общая дистанция токена\n",
    "        self.sentence = sentence  # накопленное высказывание (в данном случае это просто слово эталона)\n",
    "\n",
    "# функция вычисления евклидова расстояния между двумя векторами:        \n",
    "def distance(X, Y):\n",
    "    #------------------------TODO-----------------------------\n",
    "    result = float(np.sqrt(pow(X - Y, 2))) \n",
    "    #---------------------------------------------------------\n",
    "    return result\n",
    "\n",
    "\n",
    "def recognize(filename, features, graph):\n",
    "    print(\"Recognizing file '{}', samples={}\".format(filename, features.nSamples))\n",
    "\n",
    "    startState = graph[0]\n",
    "    activeTokens = [Token(startState), ]\n",
    "    nextTokens = []\n",
    "\n",
    "    for frame in range(features.nSamples):\n",
    "        ftrCurrentFrameRecord = features.readvec()\n",
    "        for token in activeTokens:\n",
    "            for transitionState in token.state.nextStates:\n",
    "                #-------------------- TODO ------------------------------------------\n",
    "                # 1. создаем новый токен\n",
    "                # 2. вычисляем дистанцию токена для текущего кадра записи\n",
    "                # 3. добавляем к nextTokens созданный новый токен\n",
    "                newToken = Token(transitionState, token.dist, token.sentence)\n",
    "                newToken.dist += distance(ftrCurrentFrameRecord, transitionState.ftr)\n",
    "                nextTokens.append(newToken)\n",
    "                #--------------------------------------------------------------------\n",
    "        activeTokens = nextTokens\n",
    "        nextTokens = []\n",
    "\n",
    "    # поиск финальных токенов:\n",
    "    finalTokens = []\n",
    "    for token in activeTokens:\n",
    "        #----------------- TODO -------------------------\n",
    "        if token.state.isFinal:\n",
    "            finalTokens.append(token)\n",
    "        #------------------------------------------------\n",
    "    \n",
    "    # поиск наилучшего финального токена:\n",
    "    winToken = None\n",
    "    #-------------------- TODO -----------------------\n",
    "    minDist = finalTokens[0].dist\n",
    "    for token in finalTokens:\n",
    "        if token.dist <= minDist:\n",
    "            winToken = token\n",
    "            minDist = token.dist\n",
    "    #-------------------------------------------------\n",
    "    \n",
    "    # отображение параметров победившего токена:\n",
    "    print('-'*50)\n",
    "    print(\"WIN TOKEN: state.word = '{}', dist = {}, \".format(winToken.state.word, round(winToken.dist, 3)))\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание всех классов и функций окончено, остается только запустить нашу программу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognizing file 'record1', samples=4\n",
      "--------------------------------------------------\n",
      "WIN TOKEN: state.word = 'etalon_Net', dist = 0.4, \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "etalons = \"ark,t:etalons_mfcc.txtftr\"   # файл с признаками эталонов\n",
    "record = \"ark,t:record_mfcc.txtftr\"    # файл с признаками записи\n",
    "\n",
    "# загрузка графа:\n",
    "graph = load_graph(etalons)\n",
    "\n",
    "for filename, features in FtrFile.FtrDirectoryReader(record):\n",
    "    recognize(filename, features, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки посчитайте DTW в ручную и сравните полученный результат."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
